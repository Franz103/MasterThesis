{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46344315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\python38\\lib\\site-packages (from pytorch-lightning) (4.4.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (2022.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (1.23.4)\n",
      "Requirement already satisfied: future>=0.17.1 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (1.10.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-lightning) (0.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\python38\\lib\\site-packages (from pytorch-lightning) (2.10.1)\n",
      "Requirement already satisfied: requests in c:\\python38\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\python38\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.49.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (41.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.2.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.19.6)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from tqdm>=4.41.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca247db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] Die angegebene Prozedur wurde nicht gefunden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#import lightning.pytorch as pl\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, LearningRateMonitor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m _PACKAGE_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m     18\u001b[0m _PROJECT_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\callbacks\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_stats_monitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceStatsMonitor\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mearly_stopping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\callbacks\\base.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STEP_OUTPUT\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCallback\u001b[39;00m(abc\u001b[38;5;241m.\u001b[39mABC):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\utilities\\__init__.py:18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"General utilities.\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_data_to_device  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AllGatherGrad, rank_zero_info, rank_zero_only  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     AMPType,\n\u001b[0;32m     22\u001b[0m     DeviceType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     ModelSummaryMode,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\utilities\\apply_func.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _compare_version, _TORCHTEXT_AVAILABLE\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCHTEXT_AVAILABLE:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_compare_version\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.9.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\utilities\\imports.py:54\u001b[0m, in \u001b[0;36m_compare_version\u001b[1;34m(package, op, version, use_base_version)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"Compare package version with some requirements.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m>>> _compare_version(\"torch\", operator.ge, \"0.1\")\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mTrue\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     pkg \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, DistributionNotFound):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\torchtext\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_torch_home\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      8\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\_ops.py:110\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    105\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\ctypes\\__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] Die angegebene Prozedur wurde nicht gefunden"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "#os.chdir(\"../../..\")\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pytorch_lightning as pl\n",
    "#import lightning.pytorch as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba462563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Only needed for startup\\n# add time index\\ndata[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\\ndata[\"time_idx\"] -= data[\"time_idx\"].min()\\n# add additional features\\n# categories have to be strings\\ndata[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")\\ndata[\"log_volume\"] = np.log(data.volume + 1e-8)\\ndata[\"avg_volume_by_sku\"] = (\\n    data\\n    .groupby([\"time_idx\", \"sku\"], observed=True)\\n    .volume.transform(\"mean\")\\n)\\ndata[\"avg_volume_by_agency\"] = (\\n    data\\n    .groupby([\"time_idx\", \"agency\"], observed=True)\\n    .volume.transform(\"mean\")\\n)\\n# we want to encode special days as one variable and \\n# thus need to first reverse one-hot encoding\\nspecial_days = [\\n    \"easter_day\", \"good_friday\", \"new_year\", \"christmas\",\\n    \"labor_day\", \"independence_day\", \"revolution_day_memorial\",\\n    \"regional_games\", \"fifa_u_17_world_cup\", \"football_gold_cup\",\\n    \"beer_capital\", \"music_fest\"\\n]\\ndata[special_days] = (\\n    data[special_days]\\n    .apply(lambda x: x.map({0: \"-\", 1: x.name}))\\n    .astype(\"category\")\\n)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pytorch_forecasting.data.examples import get_stallion_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#data = get_stallion_data()  # load data as pandas dataframe\n",
    "data = pd.read_csv('stallion.csv')\n",
    "\"\"\" \n",
    "# Only needed for startup\n",
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "# add additional features\n",
    "# categories have to be strings\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = (\n",
    "    data\n",
    "    .groupby([\"time_idx\", \"sku\"], observed=True)\n",
    "    .volume.transform(\"mean\")\n",
    ")\n",
    "data[\"avg_volume_by_agency\"] = (\n",
    "    data\n",
    "    .groupby([\"time_idx\", \"agency\"], observed=True)\n",
    "    .volume.transform(\"mean\")\n",
    ")\n",
    "# we want to encode special days as one variable and \n",
    "# thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\", \"good_friday\", \"new_year\", \"christmas\",\n",
    "    \"labor_day\", \"independence_day\", \"revolution_day_memorial\",\n",
    "    \"regional_games\", \"fifa_u_17_world_cup\", \"football_gold_cup\",\n",
    "    \"beer_capital\", \"music_fest\"\n",
    "]\n",
    "data[special_days] = (\n",
    "    data[special_days]\n",
    "    .apply(lambda x: x.map({0: \"-\", 1: x.name}))\n",
    "    .astype(\"category\")\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b04d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"stallion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58fd38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Agency_22</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>52.2720</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1168.903668</td>\n",
       "      <td>1069.166193</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.532566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.956461</td>\n",
       "      <td>2613.377501</td>\n",
       "      <td>103.805460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>Agency_37</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>26.505000</td>\n",
       "      <td>1852.273642</td>\n",
       "      <td>1611.466298</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>13.000635</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>1361.511918</td>\n",
       "      <td>0.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237</td>\n",
       "      <td>Agency_59</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>812.9214</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>22.219737</td>\n",
       "      <td>1270.795012</td>\n",
       "      <td>1197.184260</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>5.792496</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.700634</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>2041.909586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>316.4400</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.360000</td>\n",
       "      <td>1176.155397</td>\n",
       "      <td>1082.757488</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>7.940950</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.757134</td>\n",
       "      <td>2613.377501</td>\n",
       "      <td>125.690220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>420.9093</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>24.079012</td>\n",
       "      <td>1327.003396</td>\n",
       "      <td>1207.822992</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.981168</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.042417</td>\n",
       "      <td>1179.728165</td>\n",
       "      <td>1638.463500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     agency     sku    volume        date  industry_volume  \\\n",
       "0           0  Agency_22  SKU_01   52.2720  2013-01-01        492612703   \n",
       "1         238  Agency_37  SKU_04    0.0000  2013-01-01        492612703   \n",
       "2         237  Agency_59  SKU_03  812.9214  2013-01-01        492612703   \n",
       "3         236  Agency_11  SKU_01  316.4400  2013-01-01        492612703   \n",
       "4         235  Agency_05  SKU_05  420.9093  2013-01-01        492612703   \n",
       "\n",
       "   soda_volume  avg_max_temp  price_regular  price_actual  ...  \\\n",
       "0    718394219     25.845238    1168.903668   1069.166193  ...   \n",
       "1    718394219     26.505000    1852.273642   1611.466298  ...   \n",
       "2    718394219     22.219737    1270.795012   1197.184260  ...   \n",
       "3    718394219     25.360000    1176.155397   1082.757488  ...   \n",
       "4    718394219     24.079012    1327.003396   1207.822992  ...   \n",
       "\n",
       "   football_gold_cup  beer_capital  music_fest discount_in_percent timeseries  \\\n",
       "0                  -             -           -            8.532566          0   \n",
       "1                  -             -           -           13.000635          5   \n",
       "2                  -             -           -            5.792496          9   \n",
       "3                  -             -           -            7.940950         14   \n",
       "4                  -             -           -            8.981168         22   \n",
       "\n",
       "  time_idx month log_volume avg_volume_by_sku avg_volume_by_agency  \n",
       "0        0     1   3.956461       2613.377501           103.805460  \n",
       "1        0     1 -18.420681       1361.511918             0.549900  \n",
       "2        0     1   6.700634       1225.306376          2041.909586  \n",
       "3        0     1   5.757134       2613.377501           125.690220  \n",
       "4        0     1   6.042417       1179.728165          1638.463500  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fa076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.10.0 in c:\\python38\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: pytorch_lightning==1.5.0 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (1.5.0)\n",
      "Requirement already satisfied: opacus==0.14.0 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (0.14.0)\n",
      "Requirement already satisfied: pytorch-forecasting==0.10.3 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\python38\\lib\\site-packages (from torch==1.10.0) (4.4.0)\n",
      "Requirement already satisfied: future>=0.17.1 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (2.10.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (6.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (2022.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (1.23.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (4.64.1)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from pytorch_lightning==1.5.0) (0.3.1)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in c:\\python38\\lib\\site-packages (from pytorch_lightning==1.5.0) (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.2 in c:\\python38\\lib\\site-packages (from opacus==0.14.0) (1.9.2)\n",
      "Requirement already satisfied: matplotlib in c:\\python38\\lib\\site-packages (from pytorch-forecasting==0.10.3) (3.6.1)\n",
      "Requirement already satisfied: statsmodels in c:\\python38\\lib\\site-packages (from pytorch-forecasting==0.10.3) (0.13.2)\n",
      "Requirement already satisfied: optuna<3.0.0,>=2.3.0 in c:\\python38\\lib\\site-packages (from pytorch-forecasting==0.10.3) (2.10.1)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.24 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-forecasting==0.10.3) (0.24.2)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in c:\\python38\\lib\\site-packages (from pytorch-forecasting==0.10.3) (1.5.0)\n",
      "Requirement already satisfied: requests in c:\\python38\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (2.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\python38\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (3.8.4)\n",
      "Requirement already satisfied: alembic in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (1.10.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (6.7.0)\n",
      "Requirement already satisfied: cliff in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (4.2.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\python38\\lib\\site-packages (from optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (1.4.41)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=17.0->pytorch_lightning==1.5.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python38\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python38\\lib\\site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3) (2022.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python38\\lib\\site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python38\\lib\\site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3) (3.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (41.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (2.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (1.49.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (3.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (2.2.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (3.19.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.5.0) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from tqdm>=4.41.0->pytorch_lightning==1.5.0) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib->pytorch-forecasting==0.10.3) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib->pytorch-forecasting==0.10.3) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib->pytorch-forecasting==0.10.3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python38\\lib\\site-packages (from matplotlib->pytorch-forecasting==0.10.3) (4.37.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python38\\lib\\site-packages (from matplotlib->pytorch-forecasting==0.10.3) (9.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\python38\\lib\\site-packages (from statsmodels->pytorch-forecasting==0.10.3) (0.5.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\python38\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (2.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.5.0) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python38\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (1.1.3.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (2.1.1)\n",
      "Requirement already satisfied: Mako in c:\\python38\\lib\\site-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (1.2.3)\n",
      "Requirement already satisfied: importlib-resources in c:\\python38\\lib\\site-packages (from alembic->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (5.10.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\franz schramm\\appdata\\roaming\\python\\python38\\site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (2.4.3)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\python38\\lib\\site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (3.4.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\python38\\lib\\site-packages (from cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (4.0.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\python38\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\python38\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (1.8.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\python38\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (3.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (3.9.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.5.0) (3.2.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3) (5.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch==1.10.0 pytorch_lightning==1.5.0 opacus==0.14.0 pytorch-forecasting==0.10.3 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eef6fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franz Schramm\\AppData\\Local\\Temp\\ipykernel_2588\\2662174756.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  total_demand = data.groupby(['date']).sum()\n",
      "C:\\Users\\Franz Schramm\\AppData\\Local\\Temp\\ipykernel_2588\\2662174756.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  total_demand_SKU1 = data[data['sku']=='SKU_01'].groupby(['date']).sum()\n"
     ]
    }
   ],
   "source": [
    "total_demand = data.groupby(['date']).sum()\n",
    "total_demand_SKU1 = data[data['sku']=='SKU_01'].groupby(['date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c935f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2013-01-01    135895.630074\n",
      "2013-02-01    151682.860500\n",
      "2013-03-01    167183.221500\n",
      "2013-04-01    182822.780250\n",
      "2013-05-01    191781.605250\n",
      "2013-06-01    166922.658750\n",
      "2013-07-01    162372.330000\n",
      "2013-08-01    166792.500000\n",
      "2013-09-01    136524.577500\n",
      "2013-10-01    158416.517337\n",
      "2013-11-01    149315.334079\n",
      "2013-12-01    183455.664000\n",
      "2014-01-01    135958.231423\n",
      "2014-02-01    165563.999250\n",
      "2014-03-01    185342.148000\n",
      "2014-04-01    207929.030250\n",
      "2014-05-01    163688.798250\n",
      "2014-06-01    177104.205000\n",
      "2014-07-01    170066.311500\n",
      "2014-08-01    179567.172000\n",
      "2014-09-01    168547.827000\n",
      "2014-10-01    169295.292000\n",
      "2014-11-01    154309.320000\n",
      "2014-12-01    191000.047500\n",
      "2015-01-01    141813.612000\n",
      "2015-02-01    154303.596000\n",
      "2015-03-01    225282.915000\n",
      "2015-04-01    199092.922500\n",
      "2015-05-01    193412.014500\n",
      "2015-06-01    177996.747000\n",
      "2015-07-01    182649.606000\n",
      "2015-08-01    178917.123000\n",
      "2015-09-01    176151.684000\n",
      "2015-10-01    156728.520000\n",
      "2015-11-01    155066.400000\n",
      "2015-12-01    186305.731500\n",
      "2016-01-01    120709.224000\n",
      "2016-02-01    135425.304000\n",
      "2016-03-01    164342.733000\n",
      "2016-04-01    181457.376000\n",
      "2016-05-01    177429.366000\n",
      "2016-06-01    174034.981500\n",
      "2016-07-01    184762.629000\n",
      "2016-08-01    181595.299500\n",
      "2016-09-01    161290.114500\n",
      "2016-10-01    150817.464000\n",
      "2016-11-01    155224.615500\n",
      "2016-12-01    162884.091000\n",
      "2017-01-01    113500.008000\n",
      "2017-02-01    136985.139000\n",
      "2017-03-01    156656.910000\n",
      "2017-04-01    169747.714500\n",
      "2017-05-01    189908.164500\n",
      "2017-06-01    172170.574500\n",
      "2017-07-01    162896.080500\n",
      "2017-08-01    169604.706000\n",
      "2017-09-01    162633.523500\n",
      "2017-10-01    173405.124000\n",
      "2017-11-01    117425.271000\n",
      "2017-12-01    141274.797000\n",
      "Name: volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "total_demand_SKU1.head()\n",
    "print(total_demand_SKU1['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d3cb3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 Loss: 0.01344522\n",
      "Epoch:  10 Loss: 0.0182096716\n",
      "[0.4221948981285095, 0.4162837266921997, 0.41394150257110596, 0.40216755867004395, 0.42415234446525574, 0.40114644169807434, 0.39620453119277954, 0.4490737318992615, 0.4612337350845337, 0.45865434408187866, 0.44080817699432373, 0.4318125247955322, 0.42452743649482727, 0.419669508934021, 0.40379416942596436, 0.39503392577171326, 0.4164280891418457, 0.3815484941005707, 0.3721908926963806, 0.3919822573661804, 0.4193766713142395, 0.431674599647522, 0.43282851576805115, 0.4383569061756134, 0.43699443340301514, 0.41880232095718384, 0.3995160162448883, 0.39338362216949463, 0.39870625734329224, 0.36695605516433716, 0.3675641417503357, 0.3865888714790344, 0.4097031056880951, 0.4376550316810608, 0.43710196018218994, 0.4247936010360718, 0.4200710952281952, 0.41178372502326965, 0.415591835975647, 0.3764619827270508]\n",
      "40\n",
      "Future sales predictions: [[160694.18103337]\n",
      " [160033.41310645]\n",
      " [159771.59248535]\n",
      " [158455.46680923]\n",
      " [160912.99007519]\n",
      " [158341.32338572]\n",
      " [157788.9022633 ]\n",
      " [163698.77520904]\n",
      " [165058.05571422]\n",
      " [164769.72388965]\n",
      " [162774.8274538 ]\n",
      " [161769.26730065]\n",
      " [160954.91895265]\n",
      " [160411.88568791]\n",
      " [158637.29408808]\n",
      " [157658.04858638]\n",
      " [160049.55036073]\n",
      " [156150.60783203]\n",
      " [155104.58794453]\n",
      " [157316.92422081]\n",
      " [160379.15144749]\n",
      " [161753.84962666]\n",
      " [161882.83772505]\n",
      " [162500.81727584]\n",
      " [162348.51610861]\n",
      " [160314.94889494]\n",
      " [158159.06968891]\n",
      " [157473.5728523 ]\n",
      " [158068.55248492]\n",
      " [154519.42258752]\n",
      " [154587.39627381]\n",
      " [156714.03586778]\n",
      " [159297.81216074]\n",
      " [162422.35970449]\n",
      " [162360.53576456]\n",
      " [160984.67159881]\n",
      " [160456.77617128]\n",
      " [159530.38983839]\n",
      " [159956.07155082]\n",
      " [155582.02280421]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# The inclusion of the dataset\n",
    "\n",
    "values = total_demand_SKU1['volume'].to_numpy()\n",
    "df = pd.DataFrame(values, columns=['Sales'])\n",
    "\n",
    "\n",
    "# Preprocessing the data\n",
    "scaler = MinMaxScaler()\n",
    "sales_data = scaler.fit_transform(df['Sales'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare the dataset for training\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "fut_pred = 12\n",
    "train_window = 20\n",
    "\n",
    "sample_rate = 20 # TODO define dynamically\n",
    "noise_multiplier = 1.0\n",
    "max_grad_norm = 1.0\n",
    "delta = 1e-5\n",
    "\n",
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "train_inout_seq = create_inout_sequences(torch.FloatTensor(sales_data), train_window)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        print(f'Epoch: {i+1:3} Loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'Epoch: {i+1:3} Loss: {single_loss.item():10.10f}')\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "test_inputs_seq = create_inout_sequences(torch.FloatTensor(sales_data), train_window)\n",
    "\n",
    "for seq, labels in test_inputs_seq:\n",
    "    with torch.no_grad():\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                             torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        predictions.append(model(seq).item())\n",
    "print(predictions)\n",
    "print(len(predictions))\n",
    "# Inverse transform the predictions to get the actual values\n",
    "#actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1, 1))\n",
    "actual_predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "\n",
    "print('Future sales predictions:', actual_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c871d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franz Schramm\\AppData\\Roaming\\Python\\Python38\\site-packages\\opacus\\privacy_engine.py:645: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Franz Schramm\\AppData\\Roaming\\Python\\Python38\\site-packages\\opacus\\privacy_engine.py:229: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 Loss: 0.01594876\n",
      "Epoch:  10 Loss: 0.0173399001\n",
      "[0.4295169413089752, 0.42190954089164734, 0.4194563329219818, 0.405042439699173, 0.43459588289260864, 0.4043896496295929, 0.39969363808631897, 0.46844205260276794, 0.48066800832748413, 0.47462159395217896, 0.4500143229961395, 0.4383583962917328, 0.42926886677742004, 0.4236525595188141, 0.4041799306869507, 0.3950488269329071, 0.4245602488517761, 0.3798213303089142, 0.37113770842552185, 0.39917948842048645, 0.4341317117214203, 0.4478030204772949, 0.4472029507160187, 0.4527978301048279, 0.4494481682777405, 0.4249824583530426, 0.4008294343948364, 0.3948219120502472, 0.4032851755619049, 0.36359313130378723, 0.36800023913383484, 0.39447021484375, 0.4237481653690338, 0.4575291872024536, 0.4536202549934387, 0.43587687611579895, 0.42925921082496643, 0.4183315634727478, 0.4234873950481415, 0.3733082711696625]\n",
      "40\n",
      "Future sales predictions: [[161512.66030527]\n",
      " [160662.2829719 ]\n",
      " [160388.05625358]\n",
      " [158776.82936795]\n",
      " [162080.39915997]\n",
      " [158703.85859631]\n",
      " [158178.92477469]\n",
      " [165863.82240098]\n",
      " [167230.47527275]\n",
      " [166554.58949695]\n",
      " [163803.91721615]\n",
      " [162500.98384535]\n",
      " [161484.92981298]\n",
      " [160857.122661  ]\n",
      " [158680.41560325]\n",
      " [157659.7142815 ]\n",
      " [160958.58681329]\n",
      " [155957.54044254]\n",
      " [154986.85994512]\n",
      " [158121.45163041]\n",
      " [162028.51275711]\n",
      " [163556.73139233]\n",
      " [163489.65385001]\n",
      " [164115.06573241]\n",
      " [163740.63079591]\n",
      " [161005.78261871]\n",
      " [158305.88738782]\n",
      " [157634.34907627]\n",
      " [158580.39727432]\n",
      " [154143.50518237]\n",
      " [154636.14450708]\n",
      " [157595.03534015]\n",
      " [160867.80976087]\n",
      " [164643.95058284]\n",
      " [164206.99877725]\n",
      " [162223.5923063 ]\n",
      " [161483.85044254]\n",
      " [160262.32625484]\n",
      " [160838.66009634]\n",
      " [155229.49175849]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# The inclusion of the dataset\n",
    "\n",
    "values = total_demand_SKU1['volume'].to_numpy()\n",
    "df = pd.DataFrame(values, columns=['Sales'])\n",
    "\n",
    "\n",
    "# Preprocessing the data\n",
    "scaler = MinMaxScaler()\n",
    "sales_data = scaler.fit_transform(df['Sales'].values.reshape(-1, 1))\n",
    "\n",
    "# Prepare the dataset for training\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "fut_pred = 12\n",
    "train_window = 20\n",
    "batch_size = 20\n",
    "\n",
    "sample_rate = batch_size/20 # TODO define dynamically\n",
    "noise_multiplier = 1.0\n",
    "max_grad_norm = 1.0\n",
    "delta = 1e-5\n",
    "epsilon = 1\n",
    "\n",
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    sales_data,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,)\n",
    "\n",
    "# Attach PrivacyEngine to the optimizer\n",
    "privacy_engine = PrivacyEngine(module=model,max_grad_norm=max_grad_norm,sample_rate=sample_rate,target_delta=delta,\n",
    "    target_epsilon=epsilon,\n",
    "    epochs=epochs,)\n",
    "\n",
    "\n",
    "train_inout_seq = create_inout_sequences(torch.FloatTensor(sales_data), train_window)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        print(f'Epoch: {i+1:3} Loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'Epoch: {i+1:3} Loss: {single_loss.item():10.10f}')\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "test_inputs_seq = create_inout_sequences(torch.FloatTensor(sales_data), train_window)\n",
    "\n",
    "for seq, labels in test_inputs_seq:\n",
    "    with torch.no_grad():\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                             torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        predictions.append(model(seq).item())\n",
    "print(predictions)\n",
    "print(len(predictions))\n",
    "# Inverse transform the predictions to get the actual values\n",
    "#actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:]).reshape(-1, 1))\n",
    "actual_predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "\n",
    "print('Future sales predictions:', actual_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91c0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
